# Do androids read about electric sheep? Machine reading comprehension algorithms

[![Code4Life logo](https://code4life.pl/assets/images/code4life-logo.png)](https://it.roche.pl/)

## Research papers

### Stanford Question Answering Dataset (SQuAD)

Papers: https://arxiv.org/pdf/1606.05250.pdf (2016), https://arxiv.org/pdf/1806.03822.pdf (2018)  
Website: https://rajpurkar.github.io/SQuAD-explorer/  
Leaderboard: see the main page of the website

### Reading Comprehension with Multiple Hops (QAnagaroo)

Paper: https://arxiv.org/pdf/1710.06481.pdf (2018)  
Website: https://qangaroo.cs.ucl.ac.uk/  
Leaderboard: https://qangaroo.cs.ucl.ac.uk/leaderboard.html

### NarrativeQA Reading Comprehension Challenge (NarrativeQA)

Paper: https://arxiv.org/pdf/1712.07040.pdf (2017)  
Website: https://github.com/deepmind/narrativeqa/  
Leaderboard: https://paperswithcode.com/sota/reading-comprehension-narrativeqa (unofficial)

## Other sources

- [Reading comprehension definition](https://en.wikipedia.org/wiki/Reading_comprehension)
- [Similarity metrics (BLEU, METEOR, ROUGE)](https://medium.com/explorations-in-language-and-learning/metrics-for-nlg-evaluation-c89b6a781054)

## Recommended materials

### NLP websites

The following websites aggregate latest research papers and datasets, grouped by NLP tasks:

- [NLP Progress](http://nlpprogress.com/)
- [Modern Deep Learning Techniques Applied to NLP](https://nlpoverview.com/)
- [Papers With Code - NLP](https://paperswithcode.com/area/natural-language-processing)

### Videos

- [Yoav Goldberg: The missing elements in NLP (spaCy IRL 2019)](https://youtu.be/e12danHhlic)
- [Mark Neumann: ScispaCy: A spaCy pipeline & models for scientific & biomedical text (spaCy IRL 2019)](https://youtu.be/2_HSKDALwuw)
- [Peter Baumgartner: Applied NLP: Lessons from the Field (spaCy IRL 2019)](https://youtu.be/QRGMJWwOU94)

### AI skepticism

[Why A.I. is a big fat lie](https://bigthink.com/technology-innovation/why-a-i-is-a-big-fat-lie)

> (...) we have very little insight into how our brains pull off what they pull off.
> Replicating a brain neuron-by-neuron is a science fiction "what if" pipe dream.
> And introspection – when you think about how you think – is interesting, big time,
> but ultimately tells us precious little about what's going on in there.

> Your common sense is more amazing – and unachievable – than your common sense can
> sense. You're amazing. Your ability to think abstractly and "understand" the world
> around you might feel simple in your moment-to-moment experience, but it's incredibly
> complex. That experience of simplicity is either a testament to how adept your
> uniquely human brain is or a great illusion that's intrinsic to the human
> condition – or probably both.

> The trick is to take a moment to think about this difference. Our own personal experiences
> of being one of those smart creatures called a human is what catches us in a thought trap.
> Our very particular and very impressive capabilities are hidden from ourselves beneath
> a veil of a conscious experience that just kind of feels like "clarity." It feels simple,
> but under the surface, it's oh so complex. Replicating our "general common sense" is
> a fanciful notion that no technological advancements have ever moved us towards in any
> meaningful way.

[How IBM Watson Overpromised and Underdelivered on AI Health Care](https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care)

> In many attempted applications, Watson’s NLP struggled to make sense of medical text—as
> have many other AI systems. “We’re doing incredibly better with NLP than we were five years
> ago, yet we’re still incredibly worse than humans,” says Yoshua Bengio, a professor of
> computer science at the University of Montreal and a leading AI researcher. **In medical
> text documents, Bengio says, AI systems can’t understand ambiguity and don’t pick up on
> subtle clues that a human doctor would notice.** Bengio says current NLP technology can
> help the health care system: "It doesn’t have to have full understanding to do something
> incredibly useful," he says. But no AI built so far can match a human doctor’s comprehension
> and insight. "No, we’re not there," he says.

> Watson learned fairly quickly how to scan articles about clinical studies and determine
> the basic outcomes. **But it proved impossible to teach Watson to read the articles 
> the way a doctor would.** "The information that physicians extract from an article, that
> they use to change their care, may not be the major point of the study," Kris says.
> Watson’s thinking is based on statistics, so all it can do is gather statistics about
> main outcomes, explains Kris. "But doctors don’t work that way."

[DeepMind's Losses and the Future of Artificial Intelligence](https://www.wired.com/story/deepminds-losses-future-artificial-intelligence/)

> Researchers in machine learning now often ask, “How can machines optimize complex problems
> using massive amounts of data?” We might also ask, “How do children acquire language and
> come to understand the world, using less power and data than current AI systems do?” If
> we spent more time, money, and energy on the latter question than the former, we might
> get to artificial general intelligence a lot sooner.

[Deep Learning: A Critical Appraisal](https://arxiv.org/pdf/1801.00631v1.pdf)

> What exactly is deep learning, and what has its shown about the nature of intelligence?
> What can we expect it to do, and where might we expect it to break down? How close or
> far are we from “artificial general intelligence”, and a point at which machines show a
> human-like flexibility in solving unfamiliar problems? The purpose of this paper is both
> to temper some irrational exuberance and also to consider what we as a field might need
> to move forward. 
