{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Basic NLP operations\n",
    "\n",
    "1. Lemmatization\n",
    "1. Part-of-speech (POS) tagging\n",
    "1. Dependency parsing\n",
    "1. Rule-based pattern matching\n",
    "1. Named entity recognition (NER)\n",
    "1. Word embeddings\n",
    "\n",
    "## Tools\n",
    "- Python 3\n",
    "- spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'''She goes for a walk every day.\n",
    "           He was going to the cinema in the evening.\n",
    "           They have already gone to work.\n",
    "           I took my coffee to go and went home.'''\n",
    "word_to_find = u'go'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    if token.lemma_ != word_to_find:\n",
    "        continue\n",
    "        \n",
    "    print(f'{token.text:<8} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'The sky above the port was the color of television, tuned to a dead channel.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:<12} {token.pos_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'Bob never took Spanish at school.'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rule-based pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'''Corrective actions to previous audit findings are not implemented in a timely manner or\n",
    "           are not always documented. There are even some finding that were never discussed within the team.'''\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "negated_verb_pattern = [ {'DEP': 'neg'}, {'POS': 'VERB'} ]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('NEGATED_VERB', None, negated_verb_pattern)\n",
    "matches = matcher(doc)\n",
    "\n",
    "for rule_id, start_token, end_token in matches:\n",
    "    print(doc[start_token:end_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Token attributes - https://spacy.io/usage/linguistic-features#adding-patterns-attributes\n",
    "#    DEP - syntactic dependency\n",
    "#    OP  - quantifier (`?` means optional)\n",
    "\n",
    "# Dependency tokens - https://stackoverflow.com/a/40288324/95\n",
    "#    neg    - negation modifier\n",
    "#    advmod - adverbial modifier\n",
    "\n",
    "# {'DEP': 'advmod', 'OP': '?'}, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'Marek Grzenkowicz came to the Devoxx conference from Poland yesterday around 11 AM.'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "# Supported entity types: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# larger models, with word vectors\n",
    "# nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def most_similar(word, num=5):\n",
    "    filtered_words = [w\n",
    "                      for w in word.vocab\n",
    "                      if w.is_lower == word.is_lower\n",
    "                      and w.prob >= -15]\n",
    "    sorted_by_similarity = sorted(filtered_words, key=lambda w: word.similarity(w), reverse=True)\n",
    "    result = [w.lower_ for w in sorted_by_similarity[:num]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(most_similar(nlp.vocab[u'dog']))\n",
    "print(most_similar(nlp.vocab[u'cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "diff = nlp.vocab[u'dog'] - nlp.vocab[u'wolf']\n",
    "print(most_similar(diff))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
