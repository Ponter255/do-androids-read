{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Basic NLP operations\n",
    "\n",
    "1. Lemmatization\n",
    "1. Part-of-speech (POS) tagging\n",
    "1. Dependency parsing\n",
    "1. Rule-based pattern matching\n",
    "1. Named entity recognition (NER)\n",
    "1. Word embeddings\n",
    "\n",
    "## Tools\n",
    "- Python 3\n",
    "- spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'''She goes for a walk every day.\n",
    "           He was going to the cinema in the evening.\n",
    "           They have already gone to work.\n",
    "           I took my coffee to go and went home.'''\n",
    "word_to_find = u'go'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    if token.lemma_ != word_to_find:\n",
    "        continue\n",
    "        \n",
    "    print(f'{token.text:<8} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'The sky above the port was the color of television, tuned to a dead channel.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:<12} {token.pos_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'Bob never took Spanish at school.'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rule-based pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'''Corrective actions to previous audit findings are not implemented in a timely manner or\n",
    "           are not always documented. There are even some finding that were never discussed within the team.'''\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "negated_verb_pattern = [ {'DEP': 'neg'}, {'POS': 'VERB'} ]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('NEGATED_VERB', None, negated_verb_pattern)\n",
    "matches = matcher(doc)\n",
    "\n",
    "for rule_id, start_token, end_token in matches:\n",
    "    print(doc[start_token:end_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Token attributes - https://spacy.io/usage/linguistic-features#adding-patterns-attributes\n",
    "#    DEP - syntactic dependency\n",
    "#    OP  - quantifier (`?` means optional)\n",
    "\n",
    "# Dependency tokens - https://stackoverflow.com/a/40288324/95\n",
    "#    neg    - negation modifier\n",
    "#    advmod - adverbial modifier\n",
    "\n",
    "# {'DEP': 'advmod', 'OP': '?'}, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = u'Marek Grzenkowicz came to the Devoxx conference from Poland yesterday around 11 AM.'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "# Supported entity types: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')  # larger models, with word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "word_dog = nlp.vocab[u'dog']\n",
    "\n",
    "print(word_dog.vector[:42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f'length = {len(word_dog.vector)}')\n",
    "print(f'min    = {min(word_dog.vector)}')\n",
    "print(f'max    = {max(word_dog.vector)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cosine similarity\n",
    "\n",
    "TODO: add image; use Wolfram to draw it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: use `cosine_similarity` instead\n",
    "\n",
    "print(word_dog.similarity(nlp.vocab[u'cat']))\n",
    "print(word_dog.similarity(nlp.vocab[u'hammer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arithmetic of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_similar_vectors(word_vector, vocabulary, skip_words=(), num=3):\n",
    "    result = [\n",
    "        w\n",
    "        for w in vocabulary\n",
    "        if w.prob >= -15\n",
    "        and w.is_lower\n",
    "        and any(w.vector != word_vector)\n",
    "        and w.orth_ not in skip_words\n",
    "    ]\n",
    "    result = sorted(\n",
    "        result,\n",
    "        key=lambda w: cosine_similarity([w.vector], [word_vector]),\n",
    "        reverse=True\n",
    "    )\n",
    "    return [w.orth_ for w in result[:num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(find_similar_vectors(word_dog.vector, nlp.vocab, num=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arithmetic of word vectors\n",
    "$$ \\mathit{parent} + \\mathit{woman} = \\mathit{x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = nlp.vocab[u'parent'].vector + nlp.vocab[u'woman'].vector\n",
    "print(find_similar_vectors(x, nlp.vocab, skip_words=[u'parent', u'woman']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\mathit{seawater} -\\mathit{salt} = \\mathit{x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = nlp.vocab[u'seawater'].vector - nlp.vocab[u'salt'].vector\n",
    "print(find_similar_vectors(x, nlp.vocab, skip_words=[u'seawater', u'salt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arithmetic of word vectors\n",
    "$$ \\mathit{Germany} - \\mathit{Berlin} = \\mathit{x} - \\mathit{Warsaw} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = nlp.vocab[u'germany'].vector - nlp.vocab[u'berlin'].vector + nlp.vocab[u'warsaw'].vector\n",
    "print(find_similar_vectors(x, nlp.vocab, skip_words=[u'germany', u'berlin', u'warsaw']))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
